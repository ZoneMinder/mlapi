[general]
# This is an optional file
# If specified, you can specify tokens with secret values in that file
# and onlt refer to the tokens in your main config file

#secrets=./secrets.ini
secrets=/etc/zm/secrets.ini


# port that mlapi will listen on. Default 5000
port=5000

# Maximum # of processes that will be forked
# to handle requests. Note that each process will
# have its own copy of the model, so memory can 
# build up very quickly
# This number also dictates how many requests will be executed in parallel
# The rest will be queued

# default: flask
wsgi_server=bjoern 

# if yes, will use ZM logs. Default no
use_zm_logs=yes
pyzm_overrides={'log_level_debug':5}

# If you are using bjoern, processes is always 1 
# For now, keep this to 1 if you are on a GPU
processes=1

# the secret key that will be used to sign
# JWT tokens. Make sure you change the value
# in your secrets.ini
mlapi_secret_key=!MLAPI_SECRET_KEY

# folder where images will be uploaded
# default ./images
images_path={{base_data_path}}/images

# folder where the user DB will be stored
db_path=./db

# base data path for various files the ES+OD needs
# we support in config variable substitution as well
base_data_path=/var/lib/zmeventnotification

# If yes, will allow connections to self signed certificates
# Default yes
allow_self_signed=yes

# If specified, will limit detected object size to this amount of
# the total image size passed. Can help avoiding weird detections
# You can specify as % or px. Default is px
# Remember the image is resized to 416x416 internally. better
# to keep in %
max_detection_size=70%

# You can now limit the # of detection process
# per target processor. If not specified, default is 1
# Other detection processes will wait to acquire lock

cpu_max_processes=3
tpu_max_processes=1
gpu_max_processes=1

# NEW: Time to wait in seconds per processor to be free, before
# erroring out. Default is 120 (2 mins)
cpu_max_lock_wait=120
tpu_max_lock_wait=120
gpu_max_lock_wait=120



# config for object
[object]

# If you are using legacy format (use_sequence=no) then these parameters will 
# be used during ML inferencing
#object_detection_pattern=.*
object_detection_pattern=(person|car|motorbike|bus|truck|boat)
object_min_confidence=0.3
object_framework=coral_edgetpu
object_processor=tpu
object_weights={{base_data_path}}/models/coral_edgetpu/ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite
object_labels={{base_data_path}}/models/coral_edgetpu/coco_indexed.names

# If you are using the new ml_sequence format (use_sequence=yes) then 
# you can fiddle with these parameters and look at ml_sequence later
# Note that these can be named anything. You can add custom variables, ad-infinitum


# This is a useful debugging trick. If you are chaning models and want to know which
# model detected an object, make this yes. When yes, it will prefix the model name before the
# detected object. Example: Instead of 'person', it will say '(yolo) person'
show_models=no

# Google Coral
# The mobiledet model came out in Nov 2020 and is supposed to be faster and more accurate but YMMV
tpu_object_weights_mobiledet={{base_data_path}}/models/coral_edgetpu/ssdlite_mobiledet_coco_qat_postprocess_edgetpu.tflite
tpu_object_weights_mobilenet={{base_data_path}}/models/coral_edgetpu/ssd_mobilenet_v2_coco_quant_postprocess_edgetpu.tflite
tpu_object_labels={{base_data_path}}/models/coral_edgetpu/coco_indexed.names
tpu_object_framework=coral_edgetpu
tpu_object_processor=tpu
tpu_min_confidence=0.6


# Yolo v4 on GPU (falls back to CPU if no GPU)
yolo4_object_weights={{base_data_path}}/models/yolov4/yolov4.weights
yolo4_object_labels={{base_data_path}}/models/yolov4/coco.names
yolo4_object_config={{base_data_path}}/models/yolov4/yolov4.cfg
yolo4_object_framework=opencv
yolo4_object_processor=gpu

# Yolo v3 on GPU (falls back to CPU if no GPU)
yolo3_object_weights={{base_data_path}}/models/yolov3/yolov3.weights
yolo3_object_labels={{base_data_path}}/models/yolov3/coco.names
yolo3_object_config={{base_data_path}}/models/yolov3/yolov3.cfg
yolo3_object_framework=opencv
yolo3_object_processor=gpu

# Tiny Yolo V4 on GPU (falls back to CPU if no GPU)
tinyyolo_object_config={{base_data_path}}/models/tinyyolov4/yolov4-tiny.cfg
tinyyolo_object_weights={{base_data_path}}/models/tinyyolov4/yolov4-tiny.weights
tinyyolo_object_labels={{base_data_path}}/models/tinyyolov4/coco.names
tinyyolo_object_framework=opencv
tinyyolo_object_processor=gpu



[face]

# NOTE: None of these are used if use_sequence is enabled. Ig enabled
# only values in ml_sequence are processed


face_detection_framework=dlib
face_recognition_framework=dlib
face_num_jitters=0
face_upsample_times=1
face_model=cnn
face_train_model=cnn
face_recog_dist_threshold=0.6
face_recog_knn_algo=ball_tree
known_images_path={{base_data_path}}/known_faces
unknown_images_path={{base_data_path}}/unknown_faces

unknown_face_name=unknown face
save_unknown_faces=yes
save_unknown_faces_leeway_pixels=50

[alpr]

# NOTE: None of these are used if use_sequence is enabled. Ig enabled
# only values in ml_sequence are processed


alpr_use_after_detection_only=yes
alpr_api_type=cloud

# -----| If you are using plate recognizer | ------
alpr_service=plate_recognizer
alpr_key=!PLATEREC_ALPR_KEY
platerec_stats=yes
#platerec_regions=['us','cn','kr']
platerec_min_dscore=0.1
platerec_min_score=0.2

# ----| If you are using openALPR |-----
#alpr_service=open_alpr
#alpr_key=!OPENALPR_ALPR_KEY
#openalpr_recognize_vehicle=1
#openalpr_country=us
#openalpr_state=ca
# openalpr returns percents, but we convert to between 0 and 1
#openalpr_min_confidence=0.3

# ----| If you are using openALPR command line |-----
openalpr_cmdline_binary=alpr
openalpr_cmdline_params=-j -d
openalpr_cmdline_min_confidence=0.3


[ml]
# if enabled, will not grab exclusive locks before running inferencing
# locking seems to cause issues on some unique file systems
disable_locks = no


use_sequence = yes
ml_sequence= {
		'general': {
			'model_sequence': 'object,face,alpr',
            'disable_locks': '{{disable_locks}}',

		},
		'object': {
			'general':{
				'pattern':'{{object_detection_pattern}}',
				'same_model_sequence_strategy': 'most_unique' # also 'most', 'most_unique's
			},
			'sequence': [{
				#First run on TPU with higher confidence
				'object_weights':'{{tpu_object_weights_mobiledet}}',
				'object_labels': '{{tpu_object_labels}}',
				'object_min_confidence': {{tpu_min_confidence}},
				'object_framework':'{{tpu_object_framework}}',
				'tpu_max_processes': {{tpu_max_processes}},
				'tpu_max_lock_wait': {{tpu_max_lock_wait}},
                'max_detection_size':'{{max_detection_size}}',
				'show_models':'{{show_models}}'

				
			},
			{
				# YoloV4 on GPU if TPU fails (because sequence strategy is 'first')
				'object_config':'{{yolo4_object_config}}',
				'object_weights':'{{yolo4_object_weights}}',
				'object_labels': '{{yolo4_object_labels}}',
				'object_min_confidence': {{object_min_confidence}},
				'object_framework':'{{yolo4_object_framework}}',
				'object_processor': '{{yolo4_object_processor}}',
				'gpu_max_processes': {{gpu_max_processes}},
				'gpu_max_lock_wait': {{gpu_max_lock_wait}},
				'cpu_max_processes': {{cpu_max_processes}},
				'cpu_max_lock_wait': {{cpu_max_lock_wait}},
                'max_detection_size':'{{max_detection_size}}',
				'show_models':'{{show_models}}'

			}]
		},
		'face': {
			'general':{
				'pattern': '{{face_detection_pattern}}',
				'same_model_sequence_strategy': 'first'
			},
			'sequence': [{
				'save_unknown_faces':'{{save_unknown_faces}}',
				'save_unknown_faces_leeway_pixels':{{save_unknown_faces_leeway_pixels}},
				'face_detection_framework': '{{face_detection_framework}}',
				'known_images_path': '{{known_images_path}}',
				'unknown_images_path': '{{unknown_images_path}}',
				'face_model': '{{face_model}}',
				'face_train_model': '{{face_train_model}}',
				'face_recog_dist_threshold': {{face_recog_dist_threshold}},
				'face_num_jitters': {{face_num_jitters}},
				'face_upsample_times':{{face_upsample_times}},
				'gpu_max_processes': {{gpu_max_processes}},
				'gpu_max_lock_wait': {{gpu_max_lock_wait}},
				'cpu_max_processes': {{cpu_max_processes}},
				'cpu_max_lock_wait': {{cpu_max_lock_wait}},
				'max_size':800
			}]
		},

		'alpr': {
			'general':{
				'same_model_sequence_strategy': 'first',
				'pre_existing_labels':['car', 'motorbike', 'bus', 'truck', 'boat'],
				'pattern': '{{alpr_detection_pattern}}'

			},
			'sequence': [{
				'alpr_api_type': '{{alpr_api_type}}',
				'alpr_service': '{{alpr_service}}',
				'alpr_key': '{{alpr_key}}',
				'platrec_stats': '{{platerec_stats}}',
				'platerec_min_dscore': {{platerec_min_dscore}},
				'platerec_min_score': {{platerec_min_score}},
				'max_size':1600
			}]
		}
	}

